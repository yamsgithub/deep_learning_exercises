{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can a recurrent network learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will construct a set of simple strings, and train a LSTM network, and see what sequence-concepts these networks can learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A set of simple strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remembering state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these strings, we will generate random letters, but any letter following the S must be the same as the letter following the previous R\n",
    "\n",
    "First, let's revise some Python to figure out how to generate these strings.\n",
    "\n",
    "(Later on, you can vary this function to compute different types of strings, to see what a LSTM net can do. ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put all these functions together into a function to generate a set of strings and their 0/1 labels\n",
    "\n",
    "This will be used to generate training and test data. \n",
    "\n",
    "*** after using this version, you should change this function (or define another function) to generate strings of a different type, and then go through the worksheet again ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_RS_memory_strings(n_strings, string_length, charset):\n",
    "    \"\"\"\n",
    "    n_strings : number of strings to generate\n",
    "    n : length of the string to be generated\n",
    "    charset : set of characters to use\n",
    "    specialchar : the memorize symbol (a character)\n",
    "    valid : boolean - memorisation correct if True, incorrect if false\n",
    "    \"\"\"\n",
    "    char_list = list( charset )\n",
    "    string_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    \n",
    "    for s_counter in range(0,n_strings):\n",
    "        label = random.randint(0,1)\n",
    "        this_string_list = []\n",
    "        \n",
    "        Rpos1 = random.randint(0,string_length-2) # last possible position is second-last character\n",
    "        Rpos2 = random.randint(0,string_length-2)\n",
    "        while np.abs(Rpos1 - Rpos2) < 2:\n",
    "            Rpos2 = random.randint(0,string_length-2)\n",
    "        if Rpos1 > Rpos2:\n",
    "            Rpos1, Rpos2 = (Rpos2, Rpos1) # in python you can swap variable values like this\n",
    "        for i in range(0,string_length):\n",
    "            this_string_list.append( random.choice( char_list ) )\n",
    "        this_string_list[Rpos1] = 'R'\n",
    "        this_string_list[Rpos2] = 'S'\n",
    "        if label: \n",
    "            this_string_list[Rpos2+1] = this_string_list[Rpos1+1] # memory and correct recall !\n",
    "        else:\n",
    "            while this_string_list[Rpos2+1] == this_string_list[Rpos1+1]:\n",
    "                this_string_list[Rpos2+1] = random.choice( char_list )\n",
    "        string_list.append( ''.join( this_string_list ) )\n",
    "        label_list.append( label )\n",
    "    \n",
    "    return string_list, label_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bRacSbbc',\n",
       "  'RbbbSaab',\n",
       "  'bRbcaSbc',\n",
       "  'bRbSacaa',\n",
       "  'RccScbcb',\n",
       "  'aRbSbcab',\n",
       "  'bRacacSa',\n",
       "  'accRacSb',\n",
       "  'bRaaaSbc',\n",
       "  'aRbbbSbb'],\n",
       " [0, 0, 1, 0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function ! \n",
    "# make sure the class labels are what is wanted. (Make sure you understanda what the class labels mean here.)\n",
    "\n",
    "ss, ss_labels = generate_RS_memory_strings(10, 8, 'abc')\n",
    "ss, ss_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a dict that maps characters in a string to numbers, counting up from 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This constructs and returns two dicts, that can be used to map the characters that are in the string\n",
    "# to ints, and those ints back to the characters\n",
    "\n",
    "def char_to_integers( mystring ):\n",
    "    charlist = list( set( list( mystring )))\n",
    "    nums = range(1,len(charlist)+1)\n",
    "    c2ndict = dict()\n",
    "    n2cdict = dict()\n",
    "    for c,n in zip(charlist,nums):\n",
    "        c2ndict[c]=n\n",
    "        n2cdict[n]=c\n",
    "    return c2ndict, n2cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n': 1, 'a': 2, 'l': 3, 't': 4, 'h': 5, 'p': 6, 'e': 7},\n",
       " {1: 'n', 2: 'a', 3: 'l', 4: 't', 5: 'h', 6: 'p', 7: 'e'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it\n",
    "char_to_integers('elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_int_vec( s, pad_length, code_dict):\n",
    "    \"\"\"\n",
    "    Converts a string to a vector of ints, using a character-encoding dictionary\n",
    "    \n",
    "    s : the string to convert\n",
    "    padlength : the length to pad the string to, with initial zeros\n",
    "    code : dict giving the conversion from chars to integers\n",
    "    \"\"\"\n",
    "    slen = len(s)\n",
    "    assert slen <= pad_length\n",
    "    v = np.zeros([pad_length])\n",
    "    startx = pad_length - slen\n",
    "    stringlist = list(s)\n",
    "    for i in range(0,slen):\n",
    "        v[startx + i] = code_dict[stringlist[i]]\n",
    "    return v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_nparray(strings, pad_length, char_to_integers):\n",
    "    \"\"\"\n",
    "    Converts a lest of strings to an numpy array, which can be used as training\n",
    "    or testing data\n",
    "    \n",
    "    strings : a list of strings\n",
    "    maxlen  : an integer, greater than or equal to the max length of any of the strings\n",
    "    \n",
    "    This function converts a list of n strings into a n x maxlen numpy array, containing\n",
    "    the coded strings\n",
    "    \"\"\"\n",
    "    mat = np.zeros([len(strings),pad_length])\n",
    "    for i in range(0,len(strings)):\n",
    "        mat[i,:] = string_to_int_vec( strings[i], pad_length, char_to_integers )\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'R': 2, 'S': 3, 'c': 4, 'b': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2i,i2c = char_to_integers(''.join(ss))\n",
    "c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 2., 1., 4., 3., 5., 5., 4.],\n",
       "       [2., 5., 5., 5., 3., 1., 1., 5.],\n",
       "       [5., 2., 5., 4., 1., 3., 5., 4.],\n",
       "       [5., 2., 5., 3., 1., 4., 1., 1.],\n",
       "       [2., 4., 4., 3., 4., 5., 4., 5.],\n",
       "       [1., 2., 5., 3., 5., 4., 1., 5.],\n",
       "       [5., 2., 1., 4., 1., 4., 3., 1.],\n",
       "       [1., 4., 4., 2., 1., 4., 3., 5.],\n",
       "       [5., 2., 1., 1., 1., 3., 5., 4.],\n",
       "       [1., 2., 5., 5., 5., 3., 5., 5.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test strings_to_nparray\n",
    "\n",
    "data = strings_to_nparray(ss,8,c2i)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a useful checking function is to do the back-conversion\n",
    "\n",
    "def int_vec_to_string(v,i2c):\n",
    "    \"\"\"\n",
    "    v : an array of ints, possibly with initial zeros to be ignored\n",
    "    i2c : a dict mapping ints to chars\n",
    "    \"\"\"\n",
    "    charlist = []\n",
    "    i = 0 \n",
    "    for i in range(0,v.shape[0]):\n",
    "        if v[i] > 0:\n",
    "            charlist.append( i2c[v[i]] )\n",
    "    return ''.join(charlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bRbcaSbc', 'bRbcaSbc', 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can check the conversions\n",
    "# the original string and its back-conversion from its vector-coding should be the same\n",
    "ss[2], int_vec_to_string(data[2,:],i2c), ss_labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_strings, training_label_list = generate_RS_memory_strings(5000, pad_length, set('ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings, test_label_list = generate_RS_memory_strings(5000, pad_length, set('ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['aabRbbaSba', 'RaaabaaSaa', 'aRbabSbaab', 'RbbababbSb', 'bRbbabSbab'],\n",
       " [1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_strings[:5], training_label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bRbbaabSbb', 'RbaabSaaba', 'bRabSababa', 'bbaaaRaSba', 'baabbRaSbb'],\n",
       " [1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_strings[:5], test_label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3599, 1849, 3628)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_string_set = set( training_strings )\n",
    "test_string_set = set( test_strings )\n",
    "\n",
    "# there is only a finite number of strings of length 10 - how big is the overlap between the strings in \n",
    "# the training set and the test set (or, does the training set already contain all the strings? )\n",
    "\n",
    "# we can use set intersection to find out. \n",
    "overlap = train_string_set.intersection( test_string_set)\n",
    "len(train_string_set), len( overlap ), len(test_string_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(training_label_list)\n",
    "y_test = np.asarray(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this inefficiently ensures that we have complete character codinng and decoding\n",
    "# dictionaries by scanning through the entire training set\n",
    "c2i, i2c = char_to_integers(''.join(training_strings))\n",
    "n_chars = len( c2i ) + 1 # we leave 0 as the padding symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 10), (5000, 10))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = strings_to_nparray(training_strings, pad_length, c2i)\n",
    "x_test = strings_to_nparray(test_strings, pad_length, c2i)\n",
    "(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import Embedding, Attention\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars  # the number of different characters used in the training set strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.eye(n_chars+1)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the outputs of the LSTM layer during the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check to see if the LSTM works for sequences of different lengths, even though we only trained it on sequences of length 10. And let use visualise the output of the LSTM layer at all stages of sequence processing. \n",
    "\n",
    "To do this visualisation, we will transfer the weights from the model we trained to a different model, which we use only for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lstm_outputs(lstm_ouputs, viz_string):\n",
    "    plt.imshow(lstm_ouputs)\n",
    "    plt.xticks(range(0, len(viz_string)), [c for c in viz_string])\n",
    "    plt.yticks(range(0, 10),[i for i in range(0,10)])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_lstm_outputs(lstm_outputs[0,:,:].transpose(), viz_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigation:  Now compare the heatmaps generated when you change one character of viz_string. Try changing characters that don't matter, and also characters that do, and see what changes happen in the outputs of the LSTM layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Self-help: can you look up in the matplotlib documentation (or google) to put the letters of the viz_string along the x-axis of the heatmap? This would make it easier to see what outputs are changing when ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: use the model_for_viz outputs as a matrix and multiply the matrix with these weights, to get the input to the last layer of the model at each character of the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length int sequences.\n",
    "query_input = Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Embedding lookup.\n",
    "token_embedding = Embedding(n_chars+1, output_dim=n_chars+1, name='embedding')\n",
    "# Query embeddings of shape [batch_size, Tq, dimension].\n",
    "query_embeddings = token_embedding(query_input)\n",
    "\n",
    "# LSTM layer.\n",
    "lstm_layer = LSTM(10, activation='tanh',return_sequences=True)\n",
    "# Query encoding of shape [batch_size, Tq, filters].\n",
    "query_seq_encoding = lstm_layer(query_embeddings)\n",
    "\n",
    "# Query-value attention of shape [batch_size, Tq, filters].\n",
    "query_value_attention_seq = Attention()([query_seq_encoding, query_seq_encoding])\n",
    "\n",
    "# Reduce over the sequence axis to produce encodings of shape\n",
    "# [batch_size, filters].\n",
    "#query_encoding = GlobalAveragePooling1D()(\n",
    "#    query_seq_encoding)\n",
    "#query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "#    query_value_attention_seq)\n",
    "\n",
    "# Concatenate query and document encodings to produce a DNN input layer.\n",
    "input_layer = Concatenate()([query_seq_encoding, query_value_attention_seq])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create another model, exactly similar to the LSTM model above, but which has been\n",
    "# altered to give the LSTM outputs for the whole sequence\n",
    "\n",
    "# We will not train this model at all - we are simply copying the weights of the trained model into a different\n",
    "# model that gives the complete output of the LSTM layer for the whole sequence, instead of a single yes/no prediction\n",
    "\n",
    "# Concatenate query and document encodings to produce a DNN input layer.\n",
    "decoder_lstm_layer = LSTM(10, activation='tanh')(query_value_attention_seq)\n",
    "dense_layer = Dense(1, activation='sigmoid')(decoder_lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x13afa6a20>\n"
     ]
    }
   ],
   "source": [
    "model = Model(query_input, dense_layer)\n",
    "print(model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 6)      36          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 10)     680         embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, None, 10)     0           lstm[0][0]                       \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 10)           840         attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            11          lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,567\n",
      "Trainable params: 1,567\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.eye(n_chars+1)\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x13afa6a58>,\n",
       " <tensorflow.python.keras.layers.embeddings.Embedding at 0x13afa6a20>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x13afbc320>,\n",
       " <tensorflow.python.keras.layers.dense_attention.Attention at 0x13afbcf60>,\n",
       " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x13afa6240>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x13afa60b8>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 5s 988us/sample - loss: 0.6934 - accuracy: 0.5150 - val_loss: 0.6933 - val_accuracy: 0.5114\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 1s 244us/sample - loss: 0.6926 - accuracy: 0.5150 - val_loss: 0.6931 - val_accuracy: 0.5036\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.6919 - accuracy: 0.5264 - val_loss: 0.6909 - val_accuracy: 0.5296\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 1s 238us/sample - loss: 0.6895 - accuracy: 0.5420 - val_loss: 0.6884 - val_accuracy: 0.5282\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.6861 - accuracy: 0.5460 - val_loss: 0.6861 - val_accuracy: 0.5482\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 1s 271us/sample - loss: 0.6843 - accuracy: 0.5472 - val_loss: 0.6841 - val_accuracy: 0.5450\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 1s 250us/sample - loss: 0.6825 - accuracy: 0.5446 - val_loss: 0.6839 - val_accuracy: 0.5484\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 1s 243us/sample - loss: 0.6809 - accuracy: 0.5528 - val_loss: 0.6835 - val_accuracy: 0.5520\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 1s 240us/sample - loss: 0.6792 - accuracy: 0.5596 - val_loss: 0.6813 - val_accuracy: 0.5502\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 1s 246us/sample - loss: 0.6777 - accuracy: 0.5610 - val_loss: 0.6800 - val_accuracy: 0.5628\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.6753 - accuracy: 0.5658 - val_loss: 0.6768 - val_accuracy: 0.5702\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 1s 243us/sample - loss: 0.6722 - accuracy: 0.5758 - val_loss: 0.6768 - val_accuracy: 0.5684\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 1s 242us/sample - loss: 0.6707 - accuracy: 0.5758 - val_loss: 0.6724 - val_accuracy: 0.5826\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 1s 248us/sample - loss: 0.6670 - accuracy: 0.5850 - val_loss: 0.6763 - val_accuracy: 0.5654\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 1s 274us/sample - loss: 0.6639 - accuracy: 0.5876 - val_loss: 0.6652 - val_accuracy: 0.5866\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 1s 258us/sample - loss: 0.6587 - accuracy: 0.5932 - val_loss: 0.6649 - val_accuracy: 0.5972\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 1s 247us/sample - loss: 0.6528 - accuracy: 0.6076 - val_loss: 0.6571 - val_accuracy: 0.5872\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 1s 266us/sample - loss: 0.6446 - accuracy: 0.6116 - val_loss: 0.6528 - val_accuracy: 0.6136\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 1s 254us/sample - loss: 0.6325 - accuracy: 0.6356 - val_loss: 0.6657 - val_accuracy: 0.6156\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 1s 244us/sample - loss: 0.6144 - accuracy: 0.6560 - val_loss: 0.6128 - val_accuracy: 0.6568\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 1s 261us/sample - loss: 0.5819 - accuracy: 0.6888 - val_loss: 0.6123 - val_accuracy: 0.6598\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 1s 264us/sample - loss: 0.5353 - accuracy: 0.7342 - val_loss: 0.5310 - val_accuracy: 0.7276\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 1s 248us/sample - loss: 0.4744 - accuracy: 0.7852 - val_loss: 0.5340 - val_accuracy: 0.7408\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 1s 248us/sample - loss: 0.3933 - accuracy: 0.8368 - val_loss: 0.3651 - val_accuracy: 0.8418\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 1s 251us/sample - loss: 0.2830 - accuracy: 0.8918 - val_loss: 0.2118 - val_accuracy: 0.9190\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 1s 255us/sample - loss: 0.1791 - accuracy: 0.9372 - val_loss: 0.1304 - val_accuracy: 0.9524\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 1s 281us/sample - loss: 0.1138 - accuracy: 0.9628 - val_loss: 0.0908 - val_accuracy: 0.9710\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 1s 249us/sample - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.0459 - val_accuracy: 0.9888\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.0368 - val_accuracy: 0.9896\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 1s 243us/sample - loss: 0.0486 - accuracy: 0.9856 - val_loss: 0.0223 - val_accuracy: 0.9960\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 1s 247us/sample - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.0178 - val_accuracy: 0.9972\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 1s 257us/sample - loss: 0.0206 - accuracy: 0.9954 - val_loss: 0.0100 - val_accuracy: 0.9990\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 1s 254us/sample - loss: 0.0184 - accuracy: 0.9956 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 1s 278us/sample - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0067 - val_accuracy: 0.9994\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 1s 251us/sample - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0054 - val_accuracy: 0.9994\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.0231 - accuracy: 0.9946 - val_loss: 0.0036 - val_accuracy: 0.9998\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 1s 247us/sample - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0031 - val_accuracy: 0.9998\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 1s 245us/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 1s 240us/sample - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.0021 - val_accuracy: 0.9998\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 1s 263us/sample - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 1s 238us/sample - loss: 0.0082 - accuracy: 0.9986 - val_loss: 0.0106 - val_accuracy: 0.9972\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 1s 241us/sample - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0043 - val_accuracy: 0.9984\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 1s 241us/sample - loss: 0.0070 - accuracy: 0.9988 - val_loss: 7.2438e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 1s 258us/sample - loss: 0.0114 - accuracy: 0.9982 - val_loss: 6.1803e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 1s 249us/sample - loss: 5.0235e-04 - accuracy: 1.0000 - val_loss: 4.3491e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 1s 255us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0018 - val_accuracy: 0.9998\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 2s 349us/sample - loss: 3.1958e-04 - accuracy: 1.0000 - val_loss: 2.7131e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 1s 295us/sample - loss: 0.0232 - accuracy: 0.9970 - val_loss: 5.6251e-04 - val_accuracy: 0.9998\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 1s 262us/sample - loss: 2.1007e-04 - accuracy: 1.0000 - val_loss: 1.8321e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 1s 269us/sample - loss: 0.0225 - accuracy: 0.9968 - val_loss: 0.0212 - val_accuracy: 0.9946\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer from Bahdanau et. al \n",
    "# https://arxiv.org/abs/1409.0473\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test[:10,:])\n",
    "print([int(p[0]>0.5) for p in pred])\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 4. 1. 2. 4. 2. 4. 2. 4. 2. 3. 4. 4. 4.]]\n",
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "# Now let us define a string for which we will visualise the outputs of the LSTM layer. \n",
    "# Let's use a string of length 19, say.  How long can you make this string so that the original \n",
    "# model still works?  \n",
    "\n",
    "viz_string = 'abRabababaSbbb'\n",
    "viz_vector = string_to_int_vec(viz_string, len(viz_string), c2i)\n",
    "viz_vector = viz_vector.reshape([1,viz_vector.shape[0]]) # this makes it a data set of size 1\n",
    "print(viz_vector)\n",
    "print(viz_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99961686]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(viz_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
