{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can a recurrent network learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will construct a set of simple strings, and train a LSTM network, and see what sequence-concepts these networks can learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A set of simple strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remembering state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these strings, we will generate random letters, but any letter following the S must be the same as the letter following the previous R\n",
    "\n",
    "First, let's revise some Python to figure out how to generate these strings.\n",
    "\n",
    "(Later on, you can vary this function to compute different types of strings, to see what a LSTM net can do. ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put all these functions together into a function to generate a set of strings and their 0/1 labels\n",
    "\n",
    "This will be used to generate training and test data. \n",
    "\n",
    "*** after using this version, you should change this function (or define another function) to generate strings of a different type, and then go through the worksheet again ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_RS_memory_strings(n_strings, string_length, charset):\n",
    "    \"\"\"\n",
    "    n_strings : number of strings to generate\n",
    "    n : length of the string to be generated\n",
    "    charset : set of characters to use\n",
    "    specialchar : the memorize symbol (a character)\n",
    "    valid : boolean - memorisation correct if True, incorrect if false\n",
    "    \"\"\"\n",
    "    char_list = list( charset )\n",
    "    string_label = {}\n",
    "\n",
    "    for s_counter in range(0,n_strings):\n",
    "        label = random.randint(0,1)\n",
    "        this_string_list = []\n",
    "        \n",
    "        Rpos1 = random.randint(0,string_length-2) # last possible position is second-last character\n",
    "        Rpos2 = random.randint(0,string_length-2)\n",
    "        while np.abs(Rpos1 - Rpos2) < 2:\n",
    "            Rpos2 = random.randint(0,string_length-2)\n",
    "        if Rpos1 > Rpos2:\n",
    "            Rpos1, Rpos2 = (Rpos2, Rpos1) # in python you can swap variable values like this\n",
    "        for i in range(0,string_length):\n",
    "            this_string_list.append( random.choice( char_list ) )\n",
    "        this_string_list[Rpos1] = 'R'\n",
    "        this_string_list[Rpos2] = 'S'\n",
    "        if label: \n",
    "            this_string_list[Rpos2+1] = this_string_list[Rpos1+1] # memory and correct recall !\n",
    "        else:\n",
    "            while this_string_list[Rpos2+1] == this_string_list[Rpos1+1]:\n",
    "                this_string_list[Rpos2+1] = random.choice( char_list )\n",
    "        if string_label.get(''.join( this_string_list )) is None:\n",
    "            string_label[ ''.join( this_string_list ) ] = label\n",
    "            #print(string_label)\n",
    "    \n",
    "    return list(string_label.keys()), list(string_label.values())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['baaRaSbb',\n",
       "  'RcccSbcc',\n",
       "  'bRacSbbb',\n",
       "  'cbRaScbb',\n",
       "  'aRcaScca',\n",
       "  'RcccaSca',\n",
       "  'RbSbbaca',\n",
       "  'aaaRaSba',\n",
       "  'cRaccSab',\n",
       "  'acRbbSbb'],\n",
       " [0, 0, 0, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function ! \n",
    "# make sure the class labels are what is wanted. (Make sure you understanda what the class labels mean here.)\n",
    "\n",
    "ss, ss_labels = generate_RS_memory_strings(10, 8, 'abc')\n",
    "ss, ss_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing a dict that maps characters in a string to numbers, counting up from 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This constructs and returns two dicts, that can be used to map the characters that are in the string\n",
    "# to ints, and those ints back to the characters\n",
    "\n",
    "def char_to_integers( mystring ):\n",
    "    charlist = list( set( list( mystring )))\n",
    "    nums = range(1,len(charlist)+1)\n",
    "    c2ndict = dict()\n",
    "    n2cdict = dict()\n",
    "    for c,n in zip(charlist,nums):\n",
    "        c2ndict[c]=n\n",
    "        n2cdict[n]=c\n",
    "    return c2ndict, n2cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'e': 1, 't': 2, 'p': 3, 'h': 4, 'a': 5, 'n': 6, 'l': 7},\n",
       " {1: 'e', 2: 't', 3: 'p', 4: 'h', 5: 'a', 6: 'n', 7: 'l'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it\n",
    "char_to_integers('elephant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_int_vec( s, pad_length, code_dict):\n",
    "    \"\"\"\n",
    "    Converts a string to a vector of ints, using a character-encoding dictionary\n",
    "    \n",
    "    s : the string to convert\n",
    "    padlength : the length to pad the string to, with initial zeros\n",
    "    code : dict giving the conversion from chars to integers\n",
    "    \"\"\"\n",
    "    slen = len(s)\n",
    "    assert slen <= pad_length\n",
    "    v = np.zeros([pad_length])\n",
    "    startx = pad_length - slen\n",
    "    stringlist = list(s)\n",
    "    for i in range(0,slen):\n",
    "        v[startx + i] = code_dict[stringlist[i]]\n",
    "    return v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_nparray(strings, pad_length, char_to_integers):\n",
    "    \"\"\"\n",
    "    Converts a lest of strings to an numpy array, which can be used as training\n",
    "    or testing data\n",
    "    \n",
    "    strings : a list of strings\n",
    "    maxlen  : an integer, greater than or equal to the max length of any of the strings\n",
    "    \n",
    "    This function converts a list of n strings into a n x maxlen numpy array, containing\n",
    "    the coded strings\n",
    "    \"\"\"\n",
    "    mat = np.zeros([len(strings),pad_length])\n",
    "    for i in range(0,len(strings)):\n",
    "        mat[i,:] = string_to_int_vec( strings[i], pad_length, char_to_integers )\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1, 'c': 2, 'a': 3, 'R': 4, 'S': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2i,i2c = char_to_integers(''.join(ss))\n",
    "c2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 3., 3., 4., 3., 5., 1., 1.],\n",
       "       [4., 2., 2., 2., 5., 1., 2., 2.],\n",
       "       [1., 4., 3., 2., 5., 1., 1., 1.],\n",
       "       [2., 1., 4., 3., 5., 2., 1., 1.],\n",
       "       [3., 4., 2., 3., 5., 2., 2., 3.],\n",
       "       [4., 2., 2., 2., 3., 5., 2., 3.],\n",
       "       [4., 1., 5., 1., 1., 3., 2., 3.],\n",
       "       [3., 3., 3., 4., 3., 5., 1., 3.],\n",
       "       [2., 4., 3., 2., 2., 5., 3., 1.],\n",
       "       [3., 2., 4., 1., 1., 5., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test strings_to_nparray\n",
    "\n",
    "data = strings_to_nparray(ss,8,c2i)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a useful checking function is to do the back-conversion\n",
    "\n",
    "def int_vec_to_string(v,i2c):\n",
    "    \"\"\"\n",
    "    v : an array of ints, possibly with initial zeros to be ignored\n",
    "    i2c : a dict mapping ints to chars\n",
    "    \"\"\"\n",
    "    charlist = []\n",
    "    i = 0 \n",
    "    for i in range(0,v.shape[0]):\n",
    "        if v[i] > 0:\n",
    "            charlist.append( i2c[v[i]] )\n",
    "    return ''.join(charlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bRacSbbb', 'bRacSbbb', 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can check the conversions\n",
    "# the original string and its back-conversion from its vector-coding should be the same\n",
    "ss[2], int_vec_to_string(data[2,:],i2c), ss_labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing and preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_strings, training_label_list = generate_RS_memory_strings(5000, pad_length, set('ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['abbaRbaSbb', 'babbRbSaaa', 'abRbabSbbb', 'bbRabbbSab', 'aRbaaSaaab'],\n",
       " [1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_strings[:5], training_label_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(training_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3624,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this inefficiently ensures that we have complete character codinng and decoding\n",
    "# dictionaries by scanning through the entire training set\n",
    "c2i, i2c = char_to_integers(''.join(training_strings))\n",
    "n_chars = len( c2i ) + 1 # we leave 0 as the padding symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3624, 10), (3597, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = strings_to_nparray(training_strings, pad_length, c2i)\n",
    "x_test = strings_to_nparray(test_strings, pad_length, c2i)\n",
    "(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.layers import Embedding, Attention\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars  # the number of different characters used in the training set strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.eye(n_chars+1)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the outputs of the LSTM layer during the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check to see if the LSTM works for sequences of different lengths, even though we only trained it on sequences of length 10. And let use visualise the output of the LSTM layer at all stages of sequence processing. \n",
    "\n",
    "To do this visualisation, we will transfer the weights from the model we trained to a different model, which we use only for visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigation:  Now compare the heatmaps generated when you change one character of viz_string. Try changing characters that don't matter, and also characters that do, and see what changes happen in the outputs of the LSTM layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Self-help: can you look up in the matplotlib documentation (or google) to put the letters of the viz_string along the x-axis of the heatmap? This would make it easier to see what outputs are changing when ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: use the model_for_viz outputs as a matrix and multiply the matrix with these weights, to get the input to the last layer of the model at each character of the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length int sequences.\n",
    "query_input = Input((pad_length,))\n",
    "\n",
    "# Embedding lookup.\n",
    "token_embedding = Embedding(n_chars+1, output_dim=n_chars+1, name='embedding')\n",
    "# Query embeddings of shape [batch_size, Tq, dimension].\n",
    "query_embeddings = token_embedding(query_input)\n",
    "\n",
    "# LSTM layer.\n",
    "lstm_layer = LSTM(50)\n",
    "# Query encoding of shape [batch_size, Tq, filters].\n",
    "lstm_output = lstm_layer(query_embeddings)\n",
    "dense_layer = Dense(1, activation='sigmoid')(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(query_input, dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 6)             36        \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50)                11400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 11,487\n",
      "Trainable params: 11,487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.eye(n_chars+1)\n",
    "model.layers[1].set_weights([embedding_matrix])\n",
    "model.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2899 samples, validate on 725 samples\n",
      "Epoch 1/50\n",
      "2899/2899 [==============================] - 2s 840us/sample - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6928 - val_accuracy: 0.5186\n",
      "Epoch 2/50\n",
      "2899/2899 [==============================] - 0s 133us/sample - loss: 0.6916 - accuracy: 0.5309 - val_loss: 0.6895 - val_accuracy: 0.5559\n",
      "Epoch 3/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.6861 - accuracy: 0.5592 - val_loss: 0.6821 - val_accuracy: 0.5586\n",
      "Epoch 4/50\n",
      "2899/2899 [==============================] - 0s 127us/sample - loss: 0.6792 - accuracy: 0.5678 - val_loss: 0.6799 - val_accuracy: 0.5572\n",
      "Epoch 5/50\n",
      "2899/2899 [==============================] - 0s 136us/sample - loss: 0.6774 - accuracy: 0.5692 - val_loss: 0.6759 - val_accuracy: 0.5641\n",
      "Epoch 6/50\n",
      "2899/2899 [==============================] - 0s 151us/sample - loss: 0.6751 - accuracy: 0.5726 - val_loss: 0.6762 - val_accuracy: 0.5655\n",
      "Epoch 7/50\n",
      "2899/2899 [==============================] - 0s 137us/sample - loss: 0.6723 - accuracy: 0.5781 - val_loss: 0.6747 - val_accuracy: 0.5614\n",
      "Epoch 8/50\n",
      "2899/2899 [==============================] - 0s 136us/sample - loss: 0.6701 - accuracy: 0.5764 - val_loss: 0.6687 - val_accuracy: 0.5876\n",
      "Epoch 9/50\n",
      "2899/2899 [==============================] - 0s 130us/sample - loss: 0.6666 - accuracy: 0.5809 - val_loss: 0.6705 - val_accuracy: 0.5793\n",
      "Epoch 10/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.6651 - accuracy: 0.5933 - val_loss: 0.6627 - val_accuracy: 0.5931\n",
      "Epoch 11/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.6618 - accuracy: 0.5933 - val_loss: 0.6582 - val_accuracy: 0.6097\n",
      "Epoch 12/50\n",
      "2899/2899 [==============================] - 0s 130us/sample - loss: 0.6561 - accuracy: 0.6078 - val_loss: 0.6582 - val_accuracy: 0.6069\n",
      "Epoch 13/50\n",
      "2899/2899 [==============================] - 0s 153us/sample - loss: 0.6509 - accuracy: 0.6157 - val_loss: 0.6573 - val_accuracy: 0.6193\n",
      "Epoch 14/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.6440 - accuracy: 0.6292 - val_loss: 0.6509 - val_accuracy: 0.6234\n",
      "Epoch 15/50\n",
      "2899/2899 [==============================] - 0s 144us/sample - loss: 0.6353 - accuracy: 0.6344 - val_loss: 0.6496 - val_accuracy: 0.6345\n",
      "Epoch 16/50\n",
      "2899/2899 [==============================] - 0s 144us/sample - loss: 0.6234 - accuracy: 0.6488 - val_loss: 0.6430 - val_accuracy: 0.6345\n",
      "Epoch 17/50\n",
      "2899/2899 [==============================] - 0s 129us/sample - loss: 0.6083 - accuracy: 0.6720 - val_loss: 0.6017 - val_accuracy: 0.6690\n",
      "Epoch 18/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.5836 - accuracy: 0.6895 - val_loss: 0.5806 - val_accuracy: 0.6841\n",
      "Epoch 19/50\n",
      "2899/2899 [==============================] - 0s 133us/sample - loss: 0.5529 - accuracy: 0.7209 - val_loss: 0.6401 - val_accuracy: 0.6593\n",
      "Epoch 20/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.5122 - accuracy: 0.7489 - val_loss: 0.4740 - val_accuracy: 0.7724\n",
      "Epoch 21/50\n",
      "2899/2899 [==============================] - 0s 131us/sample - loss: 0.4574 - accuracy: 0.7848 - val_loss: 0.5302 - val_accuracy: 0.7172\n",
      "Epoch 22/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.3919 - accuracy: 0.8320 - val_loss: 0.3693 - val_accuracy: 0.8497\n",
      "Epoch 23/50\n",
      "2899/2899 [==============================] - 0s 145us/sample - loss: 0.3189 - accuracy: 0.8748 - val_loss: 0.2913 - val_accuracy: 0.9021\n",
      "Epoch 24/50\n",
      "2899/2899 [==============================] - 0s 125us/sample - loss: 0.2698 - accuracy: 0.9041 - val_loss: 0.2778 - val_accuracy: 0.9062\n",
      "Epoch 25/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.2165 - accuracy: 0.9303 - val_loss: 0.1944 - val_accuracy: 0.9559\n",
      "Epoch 26/50\n",
      "2899/2899 [==============================] - 0s 144us/sample - loss: 0.1714 - accuracy: 0.9659 - val_loss: 0.1867 - val_accuracy: 0.9448\n",
      "Epoch 27/50\n",
      "2899/2899 [==============================] - 0s 129us/sample - loss: 0.1385 - accuracy: 0.9800 - val_loss: 0.1822 - val_accuracy: 0.9379\n",
      "Epoch 28/50\n",
      "2899/2899 [==============================] - 0s 132us/sample - loss: 0.1129 - accuracy: 0.9876 - val_loss: 0.1233 - val_accuracy: 0.9738\n",
      "Epoch 29/50\n",
      "2899/2899 [==============================] - 0s 127us/sample - loss: 0.0897 - accuracy: 0.9921 - val_loss: 0.0938 - val_accuracy: 0.9972\n",
      "Epoch 30/50\n",
      "2899/2899 [==============================] - 0s 128us/sample - loss: 0.0720 - accuracy: 0.9948 - val_loss: 0.0655 - val_accuracy: 0.9903\n",
      "Epoch 31/50\n",
      "2899/2899 [==============================] - 0s 139us/sample - loss: 0.0568 - accuracy: 0.9962 - val_loss: 0.1088 - val_accuracy: 0.9738\n",
      "Epoch 32/50\n",
      "2899/2899 [==============================] - 0s 132us/sample - loss: 0.0460 - accuracy: 0.9976 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2899/2899 [==============================] - 0s 133us/sample - loss: 0.0336 - accuracy: 0.9976 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2899/2899 [==============================] - 0s 131us/sample - loss: 0.0274 - accuracy: 0.9983 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2899/2899 [==============================] - 0s 128us/sample - loss: 0.0202 - accuracy: 0.9986 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2899/2899 [==============================] - 0s 130us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2899/2899 [==============================] - 0s 129us/sample - loss: 0.0120 - accuracy: 0.9993 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2899/2899 [==============================] - 0s 147us/sample - loss: 0.0060 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2899/2899 [==============================] - 0s 143us/sample - loss: 0.0046 - accuracy: 0.9997 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2899/2899 [==============================] - 0s 137us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2899/2899 [==============================] - 0s 127us/sample - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2899/2899 [==============================] - 0s 124us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.2176e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2899/2899 [==============================] - 0s 146us/sample - loss: 7.4708e-04 - accuracy: 1.0000 - val_loss: 6.4651e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2899/2899 [==============================] - 0s 147us/sample - loss: 5.5899e-04 - accuracy: 1.0000 - val_loss: 5.5240e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2899/2899 [==============================] - 0s 129us/sample - loss: 3.1633e-04 - accuracy: 1.0000 - val_loss: 4.0870e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2899/2899 [==============================] - 0s 137us/sample - loss: 6.8381e-04 - accuracy: 0.9997 - val_loss: 2.2680e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2899/2899 [==============================] - 0s 130us/sample - loss: 2.1378e-04 - accuracy: 1.0000 - val_loss: 1.5343e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2899/2899 [==============================] - 0s 127us/sample - loss: 1.1702e-04 - accuracy: 1.0000 - val_loss: 1.1196e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer from Bahdanau et. al \n",
    "# https://arxiv.org/abs/1409.0473\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length int sequences.\n",
    "query_input_att = Input((pad_length,))\n",
    "\n",
    "# Embedding lookup.\n",
    "token_embedding_att = Embedding(n_chars+1, output_dim=n_chars+1, name='embedding')\n",
    "# Query embeddings of shape [batch_size, Tq, dimension].\n",
    "query_embeddings_att = token_embedding_att(query_input_att)\n",
    "\n",
    "# LSTM layer.\n",
    "lstm_layer_att = LSTM(50, return_sequences=True)\n",
    "# Query encoding of shape [batch_size, Tq, filters].\n",
    "att_in = lstm_layer_att(query_embeddings_att)\n",
    "att_out= attention()(att_in)\n",
    "dense_layer = Dense(1, activation='sigmoid')(att_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_att = Model(query_input_att, dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 10, 6)             36        \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 10, 50)            11400     \n",
      "_________________________________________________________________\n",
      "attention_1 (attention)      (None, 50)                60        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 11,547\n",
      "Trainable params: 11,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_att.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_att.layers[1].set_weights([embedding_matrix])\n",
    "model_att.layers[1].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_att.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2899 samples, validate on 725 samples\n",
      "Epoch 1/50\n",
      "2899/2899 [==============================] - 3s 899us/sample - loss: 0.6934 - accuracy: 0.5095 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 2/50\n",
      "2899/2899 [==============================] - 0s 137us/sample - loss: 0.6929 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 3/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.6921 - accuracy: 0.5229 - val_loss: 0.6929 - val_accuracy: 0.5159\n",
      "Epoch 4/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.6908 - accuracy: 0.5326 - val_loss: 0.6916 - val_accuracy: 0.5241\n",
      "Epoch 5/50\n",
      "2899/2899 [==============================] - 0s 148us/sample - loss: 0.6882 - accuracy: 0.5405 - val_loss: 0.6904 - val_accuracy: 0.5310\n",
      "Epoch 6/50\n",
      "2899/2899 [==============================] - 0s 146us/sample - loss: 0.6864 - accuracy: 0.5436 - val_loss: 0.6879 - val_accuracy: 0.5393\n",
      "Epoch 7/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.6857 - accuracy: 0.5571 - val_loss: 0.6871 - val_accuracy: 0.5462\n",
      "Epoch 8/50\n",
      "2899/2899 [==============================] - 0s 149us/sample - loss: 0.6845 - accuracy: 0.5592 - val_loss: 0.6880 - val_accuracy: 0.5338\n",
      "Epoch 9/50\n",
      "2899/2899 [==============================] - 0s 144us/sample - loss: 0.6829 - accuracy: 0.5571 - val_loss: 0.6867 - val_accuracy: 0.5393\n",
      "Epoch 10/50\n",
      "2899/2899 [==============================] - 0s 156us/sample - loss: 0.6818 - accuracy: 0.5685 - val_loss: 0.6827 - val_accuracy: 0.5559\n",
      "Epoch 11/50\n",
      "2899/2899 [==============================] - 0s 144us/sample - loss: 0.6798 - accuracy: 0.5630 - val_loss: 0.6806 - val_accuracy: 0.5517\n",
      "Epoch 12/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.6771 - accuracy: 0.5736 - val_loss: 0.6792 - val_accuracy: 0.5683\n",
      "Epoch 13/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.6739 - accuracy: 0.5768 - val_loss: 0.6782 - val_accuracy: 0.5655\n",
      "Epoch 14/50\n",
      "2899/2899 [==============================] - 0s 140us/sample - loss: 0.6718 - accuracy: 0.5871 - val_loss: 0.6702 - val_accuracy: 0.5876\n",
      "Epoch 15/50\n",
      "2899/2899 [==============================] - 0s 136us/sample - loss: 0.6671 - accuracy: 0.5895 - val_loss: 0.6685 - val_accuracy: 0.5959\n",
      "Epoch 16/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.6620 - accuracy: 0.5950 - val_loss: 0.6620 - val_accuracy: 0.5972\n",
      "Epoch 17/50\n",
      "2899/2899 [==============================] - 0s 152us/sample - loss: 0.6566 - accuracy: 0.6068 - val_loss: 0.6631 - val_accuracy: 0.5903\n",
      "Epoch 18/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.6478 - accuracy: 0.6147 - val_loss: 0.6500 - val_accuracy: 0.6138\n",
      "Epoch 19/50\n",
      "2899/2899 [==============================] - 0s 140us/sample - loss: 0.6363 - accuracy: 0.6364 - val_loss: 0.6390 - val_accuracy: 0.6276\n",
      "Epoch 20/50\n",
      "2899/2899 [==============================] - 0s 133us/sample - loss: 0.6226 - accuracy: 0.6423 - val_loss: 0.6296 - val_accuracy: 0.6372\n",
      "Epoch 21/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.6012 - accuracy: 0.6730 - val_loss: 0.5969 - val_accuracy: 0.6800\n",
      "Epoch 22/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.5792 - accuracy: 0.6947 - val_loss: 0.5894 - val_accuracy: 0.6745\n",
      "Epoch 23/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.5521 - accuracy: 0.7230 - val_loss: 0.5490 - val_accuracy: 0.7186\n",
      "Epoch 24/50\n",
      "2899/2899 [==============================] - 0s 154us/sample - loss: 0.5126 - accuracy: 0.7520 - val_loss: 0.5158 - val_accuracy: 0.7352\n",
      "Epoch 25/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.4643 - accuracy: 0.7841 - val_loss: 0.4625 - val_accuracy: 0.7972\n",
      "Epoch 26/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.4144 - accuracy: 0.8186 - val_loss: 0.3887 - val_accuracy: 0.8234\n",
      "Epoch 27/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.3617 - accuracy: 0.8496 - val_loss: 0.4775 - val_accuracy: 0.7407\n",
      "Epoch 28/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.3130 - accuracy: 0.8789 - val_loss: 0.2800 - val_accuracy: 0.9117\n",
      "Epoch 29/50\n",
      "2899/2899 [==============================] - 0s 137us/sample - loss: 0.2623 - accuracy: 0.9093 - val_loss: 0.2711 - val_accuracy: 0.8966\n",
      "Epoch 30/50\n",
      "2899/2899 [==============================] - 0s 139us/sample - loss: 0.2236 - accuracy: 0.9341 - val_loss: 0.2312 - val_accuracy: 0.9214\n",
      "Epoch 31/50\n",
      "2899/2899 [==============================] - 0s 139us/sample - loss: 0.1863 - accuracy: 0.9572 - val_loss: 0.1723 - val_accuracy: 0.9697\n",
      "Epoch 32/50\n",
      "2899/2899 [==============================] - 0s 155us/sample - loss: 0.1580 - accuracy: 0.9796 - val_loss: 0.1573 - val_accuracy: 0.9641\n",
      "Epoch 33/50\n",
      "2899/2899 [==============================] - 0s 133us/sample - loss: 0.1322 - accuracy: 0.9841 - val_loss: 0.1289 - val_accuracy: 0.9834\n",
      "Epoch 34/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.1081 - accuracy: 0.9945 - val_loss: 0.1185 - val_accuracy: 0.9834\n",
      "Epoch 35/50\n",
      "2899/2899 [==============================] - 0s 138us/sample - loss: 0.0898 - accuracy: 0.9966 - val_loss: 0.0850 - val_accuracy: 0.9945\n",
      "Epoch 36/50\n",
      "2899/2899 [==============================] - 0s 150us/sample - loss: 0.0725 - accuracy: 0.9986 - val_loss: 0.0714 - val_accuracy: 0.9972\n",
      "Epoch 37/50\n",
      "2899/2899 [==============================] - 0s 140us/sample - loss: 0.0592 - accuracy: 0.9983 - val_loss: 0.0701 - val_accuracy: 0.9917\n",
      "Epoch 38/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.0476 - accuracy: 0.9990 - val_loss: 0.0482 - val_accuracy: 0.9959\n",
      "Epoch 39/50\n",
      "2899/2899 [==============================] - 0s 143us/sample - loss: 0.0370 - accuracy: 0.9993 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2899/2899 [==============================] - 0s 142us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2899/2899 [==============================] - 0s 146us/sample - loss: 0.0221 - accuracy: 0.9993 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2899/2899 [==============================] - 0s 132us/sample - loss: 0.0163 - accuracy: 0.9997 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2899/2899 [==============================] - 0s 141us/sample - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2899/2899 [==============================] - 0s 135us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2899/2899 [==============================] - 0s 131us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2899/2899 [==============================] - 0s 136us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2899/2899 [==============================] - 0s 134us/sample - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0191 - val_accuracy: 0.9945\n",
      "Epoch 49/50\n",
      "2899/2899 [==============================] - 0s 139us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2899/2899 [==============================] - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model_att.fit(x_train, y_train, batch_size=64, epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model_att.history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1444e4b70>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50), a,b)\n",
    "plt.legend(['Without Attn', 'With Attn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_att.predict(x_test[:10,:])\n",
    "print([int(p[0]>0.5) for p in pred])\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 2. 3. 4. 2. 4. 2. 4. 2. 4. 1. 2. 2. 2.]]\n",
      "(1, 14)\n"
     ]
    }
   ],
   "source": [
    "# Now let us define a string for which we will visualise the outputs of the LSTM layer. \n",
    "# Let's use a string of length 19, say.  How long can you make this string so that the original \n",
    "# model still works?  \n",
    "\n",
    "viz_string = 'abRabababaSbbb'\n",
    "viz_vector = string_to_int_vec(viz_string, len(viz_string), c2i)\n",
    "viz_vector = viz_vector.reshape([1,viz_vector.shape[0]]) # this makes it a data set of size 1\n",
    "print(viz_vector)\n",
    "print(viz_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (10,) but got array with shape (14,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-db0cfc028f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dl_class/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (10,) but got array with shape (14,)"
     ]
    }
   ],
   "source": [
    "model.predict(viz_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
